import streamlit as st
import pandas as pd
from thefuzz import process
import openpyxl
import numpy as np


def encontrar_inconsistencias_categoricas(series, threshold=85):
    """Encontra e agrupa valores categoricos similares."""
    unique_values = series.dropna().unique().tolist()
    if len(unique_values) < 2: return []
    processed_values = set()
    matches = []
    for val in unique_values:
        if val not in processed_values:
            similares = process.extract(val, [o for o in unique_values if o not in processed_values and o != val], limit=5)
            high_similarity = [s[0] for s in similares if s[1] > threshold]
            if high_similarity:
                grupo = tuple(sorted([val] + high_similarity))
                matches.append(grupo)
                processed_values.update(grupo)
    return matches

def encontrar_colunas_numericas_como_texto(df):
    """Identifica colunas de texto que poderiam ser num√©ricas."""
    colunas_problema = []
    for col in df.select_dtypes(include=['object']).columns:
        if df[col].dropna().empty: continue
        try:
            numeric_series = pd.to_numeric(df[col].dropna(), errors='coerce')
            if numeric_series.notna().sum() / df[col].dropna().count() > 0.8:
                colunas_problema.append(col)
        except Exception: continue
    return colunas_problema

# NOVA AN√ÅLISE: Outliers
def encontrar_outliers_numericos(series):
    """Encontra outliers usando o m√©todo IQR."""
    if pd.api.types.is_numeric_dtype(series):
        Q1 = series.quantile(0.25)
        Q3 = series.quantile(0.75)
        IQR = Q3 - Q1
        limite_inferior = Q1 - 1.5 * IQR
        limite_superior = Q3 + 1.5 * IQR
        outliers = series[(series < limite_inferior) | (series > limite_superior)]
        return outliers.tolist()
    return []

def encontrar_necessidade_de_scaling(df):
    """Verifica se features num√©ricas t√™m escalas muito diferentes."""
    numeric_cols = df.select_dtypes(include=np.number)
    if numeric_cols.shape[1] < 2: return None
    ranges = numeric_cols.max() - numeric_cols.min()
    if ranges.max() / ranges.min() > 100:
        return ranges.to_dict()
    return None

def encontrar_distribuicao_assimetrica(df, threshold=1.0):
    """Encontra features num√©ricas com alta assimetria (skewness)."""
    numeric_cols = df.select_dtypes(include=np.number)
    skewed_cols = numeric_cols.skew().filter(like='').loc[lambda x: abs(x) > threshold]
    return skewed_cols.to_dict()


st.set_page_config(layout="wide")
st.title("ü§ñ Assistente de Pr√©-processamento para Machine Learning")
st.write("Fa√ßa o upload do seu dataset (CSV ou Excel) para obter sugest√µes de tratamento para modelos de Regress√£o e Classifica√ß√£o.")

uploaded_file = st.file_uploader("Escolha um arquivo", type=['csv', 'xlsx'])

if uploaded_file is not None:
    try:
        df = pd.read_excel(uploaded_file, engine='openpyxl') if uploaded_file.name.endswith('xlsx') else pd.read_csv(uploaded_file)
        st.success("Dataset carregado com sucesso!")
        st.dataframe(df.head())
        st.header("üîç An√°lise de Pr√©-processamento para ML")

        
        with st.expander("1. Tratamento de Valores Nulos", expanded=True):
            nulos = df.isnull().sum()[lambda x: x > 0]
            if not nulos.empty:
                st.warning("Colunas com valores nulos foram encontradas!")
                st.dataframe(nulos.to_frame(name='Quantidade de Nulos'))
                st.markdown("""
                **Impacto em ML:** Muitos algoritmos (como Regress√£o Linear, SVM) n√£o aceitam valores nulos e quebrar√£o durante o treinamento (`model.fit()`).
                **Sugest√£o:** Use t√©cnicas de imputa√ß√£o (m√©dia, mediana para dados num√©ricos; moda para categ√≥ricos) ou, se a quantidade for pequena, remova as linhas.
                """)
            else: st.success("Nenhum valor nulo encontrado!")
        
        with st.expander("2. Padroniza√ß√£o de Features Categ√≥ricas", expanded=True):
            colunas_texto = df.select_dtypes(include=['object']).columns
            alguma_inconsistencia = False
            for col in colunas_texto:
                grupos = encontrar_inconsistencias_categoricas(df[col])
                if grupos:
                    alguma_inconsistencia = True
                    st.warning(f"Inconsist√™ncias encontradas na feature **'{col}'**:")
                    for g in grupos: st.write(f"- Sugest√£o de Agrupamento: `{', '.join(g)}`")
            if alguma_inconsistencia:
                st.markdown("""
                **Impacto em ML:** O modelo tratar√° 'SP' e 'S√£o Paulo' como duas cidades distintas, criando features desnecess√°rias (*feature explosion*) e piorando a performance. A padroniza√ß√£o √© essencial antes de aplicar *One-Hot Encoding*.
                **Sugest√£o:** Padronize os valores para um formato √∫nico.
                """)
            else: st.success("Nenhuma inconsist√™ncia categ√≥rica √≥bvia encontrada!")

        with st.expander("3. Convers√£o de Tipos de Dados", expanded=True):
            cols_converter = encontrar_colunas_numericas_como_texto(df)
            if cols_converter:
                st.warning("Features de texto que deveriam ser num√©ricas foram encontradas!")
                for col in cols_converter: st.write(f"- Feature **'{col}'**")
                st.markdown("""
                **Impacto em ML:** Modelos de regress√£o e classifica√ß√£o exigem *features* num√©ricas para funcionar. A convers√£o √© um passo obrigat√≥rio.
                **Sugest√£o:** Converta essas colunas para um tipo num√©rico (inteiro ou float).
                """)
            else: st.success("Todos os tipos de dados parecem consistentes.")

        with st.expander("4. An√°lise de Outliers", expanded=True):
            algum_outlier = False
            for col in df.select_dtypes(include=np.number).columns:
                outliers = encontrar_outliers_numericos(df[col])
                if outliers:
                    algum_outlier = True
                    st.warning(f"Potenciais outliers encontrados na feature **'{col}'**:")
                    st.write(f"`{outliers[:5]}`" + ('...' if len(outliers) > 5 else ''))
            if algum_outlier:
                st.markdown("""
                **Impacto em ML:** Outliers podem distorcer a escala dos dados e impactar negativamente modelos sens√≠veis a eles, como Regress√£o Linear e algoritmos baseados em dist√¢ncia (KNN, SVM), "puxando" a linha de regress√£o ou a fronteira de decis√£o.
                **Sugest√£o:** Investigue os outliers. Se forem erros, corrija-os. Se n√£o, considere remov√™-los ou usar algoritmos mais robustos a outliers (ex: RandomForest).
                """)
            else: st.success("Nenhum outlier √≥bvio detectado pelo m√©todo IQR.")

        with st.expander("5. An√°lise de Escala de Features (Feature Scaling)", expanded=True):
            ranges = encontrar_necessidade_de_scaling(df)
            if ranges:
                st.warning("Features num√©ricas com escalas muito diferentes foram detectadas!")
                st.json({k: f'Range: {v:.2f}' for k, v in ranges.items()})
                st.markdown("""
                **Impacto em ML:** Algoritmos como SVM, Regress√£o Log√≠stica, Redes Neurais e KNN s√£o sens√≠veis √† escala das features. Uma feature com escala maior (ex: sal√°rio) pode dominar o modelo, fazendo com que outras features (ex: idade) sejam ignoradas.
                **Sugest√£o:** Aplique t√©cnicas de normaliza√ß√£o (`MinMaxScaler`) ou padroniza√ß√£o (`StandardScaler`) em todas as features num√©ricas.
                """)
            else: st.success("As escalas das features num√©ricas parecem estar consistentes.")

        with st.expander("6. An√°lise de Assimetria de Dados (Skewness)", expanded=True):
            skewed = encontrar_distribuicao_assimetrica(df)
            if skewed:
                st.warning("Features com distribui√ß√£o de dados muito assim√©trica foram encontradas!")
                st.json({k: f'Skew: {v:.2f}' for k, v in skewed.items()})
                st.markdown("""
                **Impacto em ML:** Alguns modelos, como a Regress√£o Linear, t√™m melhor performance quando as features (e os erros) seguem uma distribui√ß√£o normal. Alta assimetria pode violar essa premissa.
                **Sugest√£o:** Considere aplicar transforma√ß√µes matem√°ticas (como logar√≠tmica, `np.log1p`, ou Box-Cox) para normalizar a distribui√ß√£o dos dados.
                """)
            else: st.success("As distribui√ß√µes das features num√©ricas n√£o apresentam alta assimetria.")


    except Exception as e:
        st.error(f"Ocorreu um erro ao processar o arquivo: {e}")