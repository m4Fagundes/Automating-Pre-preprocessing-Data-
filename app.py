# app.py - Vers√£o Final de Apresenta√ß√£o
# Autor: Gemini & m4fagundes
# Data: 2025-10-04 (07:35 AM)
# Descri√ß√£o: Ferramenta h√≠brida com datasets de exemplo e upload de arquivo.

import streamlit as st
import pandas as pd
import numpy as np
from io import BytesIO
from zipfile import ZipFile
from datetime import datetime
import google.generativeai as genai
import json
from sklearn.preprocessing import StandardScaler

# ==============================================================================
# 1. CONFIGURA√á√ÉO INICIAL
# ==============================================================================
st.set_page_config(layout="wide", page_title="Consultor de Dados IA", page_icon="üöÄ")

try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    LLM_OK = True
except (KeyError, AttributeError):
    LLM_OK = False

# ==============================================================================
# 2. FUN√á√ïES AUXILIARES, DE A√á√ÉO E DE AN√ÅLISE
# ==============================================================================

# --- Fun√ß√µes de A√ß√£o e Transforma√ß√£o ---
@st.cache_data
def convert_df_to_csv(df):
    return df.to_csv(index=False).encode('utf-8')

def impute_median(df, column):
    if pd.api.types.is_numeric_dtype(df[column]):
        median_val = df[column].median()
        df[column] = df[column].fillna(median_val)
        st.toast(f"Nulos em '{column}' preenchidos com a mediana ({median_val:.2f}).", icon="‚úÖ")
    return df

def remove_outliers_iqr(df, column):
    if pd.api.types.is_numeric_dtype(df[column]):
        Q1, Q3 = df[column].quantile(0.25), df[column].quantile(0.75)
        IQR = Q3 - Q1
        limite_inferior, limite_superior = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        original_rows = len(df)
        df_filtered = df[(df[column] >= limite_inferior) & (df[column] <= limite_superior)]
        removed_rows = original_rows - len(df_filtered)
        st.toast(f"{removed_rows} outliers removidos de '{column}'.", icon="‚úÖ")
        return df_filtered
    return df

def log_transform(df, column):
    if pd.api.types.is_numeric_dtype(df[column]):
        if (df[column] <= 0).any():
            st.warning(f"Coluna '{column}' cont√©m valores n√£o-positivos, log1p ser√° usado.")
            df[column] = np.log1p(df[column] - df[column].min())
        else:
            df[column] = np.log1p(df[column])
        st.toast(f"Transforma√ß√£o de Log aplicada em '{column}'.", icon="‚úÖ")
    return df

ACTION_MAP = {
    "IMPUTE_MEDIAN": impute_median,
    "REMOVE_OUTLIERS_IQR": remove_outliers_iqr,
    "LOG_TRANSFORM": log_transform,
}

# --- Fun√ß√µes de An√°lise Algor√≠tmica ---
def analisar_nulos(df):
    nulos = df.isnull().sum()[lambda x: x > 0]
    if not nulos.empty: return {"tipo": "Valores Nulos", "detalhes": nulos.to_dict()}
    return None

def analisar_outliers(series):
    if pd.api.types.is_numeric_dtype(series):
        Q1, Q3 = series.quantile(0.25), series.quantile(0.75)
        IQR = Q3 - Q1
        limite_inferior, limite_superior = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        outliers = series[(series < limite_inferior) | (series > limite_superior)]
        if not outliers.empty: return {"tipo": "Outliers", "coluna": series.name, "detalhes": {"m√©todo": "IQR", "contagem": len(outliers), "exemplos": outliers.head(3).tolist()}}
    return None

# --- Fun√ß√µes de Relat√≥rio e Intera√ß√£o com LLM ---
def formatar_achados_para_prompt(findings):
    if not findings: return "Nenhum problema algor√≠tmico significativo foi detectado."
    prompt_text = "Resultados detalhados da an√°lise algor√≠tmica:\n\n"
    for finding in findings:
        prompt_text += f"- **Tipo:** {finding.get('tipo', 'N/A')}\n"
        if 'coluna' in finding: prompt_text += f"  - **Coluna:** {finding['coluna']}\n"
        prompt_text += f"  - **Detalhes:**\n```json\n{json.dumps(finding['detalhes'], indent=2)}\n```\n\n"
    return prompt_text

def gerar_plano_de_acao_com_llm(target, user_prompt, findings_text):
    model = genai.GenerativeModel('gemini-2.0-flash')
    master_prompt = f"""
    **Persona:** Voc√™ √© um Cientista de Dados S√™nior. **Tarefa:** Analise o dossi√™ e o contexto para criar um plano de a√ß√£o em JSON. **Contexto:** - Vari√°vel Alvo: `{target}` - Objetivo: "{user_prompt}" **Dossi√™:** {findings_text} **Instru√ß√µes:** 1. Priorize os problemas mais cr√≠ticos. 2. Para cada um, crie um objeto JSON com: "action_code", "column", "justification". Use os action_codes: [`IMPUTE_MEDIAN`, `REMOVE_OUTLIERS_IQR`, `LOG_TRANSFORM`]. 3. Retorne uma lista na chave "action_plan". Apenas o JSON.
    """
    try:
        response = model.generate_content(master_prompt)
        cleaned_response = response.text.strip().replace("```json", "").replace("```", "")
        return cleaned_response
    except Exception as e:
        return json.dumps({"error": f"Erro na API: {e}"})

def gerar_texto_relatorio(file_name, original_shape, final_shape, target_column, user_context, applied_actions):
    report_date = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    actions_md_table = "| A√ß√£o Aplicada | Coluna | Justificativa da IA |\n| :--- | :--- | :--- |\n"
    if not applied_actions: actions_md_table = "Nenhuma a√ß√£o foi aplicada manualmente."
    else:
        for action in applied_actions:
            actions_md_table += f"| `{action.get('action_code', 'N/A')}` | `{action.get('column', 'N/A')}` | {action.get('justification', 'N/A')} |\n"
    report_content = f"""
# Relat√≥rio de Prepara√ß√£o de Dados
- **Dataset:** `{file_name}`
- **Data:** `{report_date}`
- **Preparado por:** Consultor de Dados IA
---
### 1. Objetivo do Modelo
> "{user_context}"
- **Vari√°vel Alvo:** `{target_column}`
### 2. Transforma√ß√µes Aplicadas
{actions_md_table}
### 3. Estado Final do Dataset
- **Shape Original:** {original_shape[0]} linhas, {original_shape[1]} colunas.
- **Shape Final:** {final_shape[0]} linhas, {final_shape[1]} colunas.
"""
    return report_content

def criar_pacote_zip(df_final, texto_relatorio, nome_arquivo_original):
    in_memory_zip = BytesIO()
    nome_base = nome_arquivo_original.split('/')[-1].split('.')[0]
    with ZipFile(in_memory_zip, 'w') as zipf:
        zipf.writestr(f"processed_{nome_base}.csv", convert_df_to_csv(df_final))
        zipf.writestr("relatorio_de_preparacao.md", texto_relatorio)
    return in_memory_zip.getvalue()

# ==============================================================================
# 4. INTERFACE PRINCIPAL E FLUXO DA APLICA√á√ÉO
# ==============================================================================

st.title("üöÄ Consultor de Dados IA")
st.write("Uma ferramenta h√≠brida que usa algoritmos e IA para criar e aplicar seu plano de tratamento de dados.")

# --- Seletor de Fonte de Dados ---
st.header("1. Escolha sua Fonte de Dados")
DATASET_OPTIONS = {
    "Selecione uma op√ß√£o": None,
    "Exemplo: Titanic (train.csv) - Para Teste de Classifica√ß√£o": "sample_datasets/test.csv",
    "Fazer upload do meu pr√≥prio arquivo (.csv ou .xlsx)": "upload"
}
selected_option_key = st.selectbox("Gostaria de usar um dataset de exemplo ou fazer o upload do seu?", options=list(DATASET_OPTIONS.keys()))
st.caption("Nota: Os datasets de exemplo s√£o os arquivos `train.csv` de competi√ß√µes, que cont√™m a vari√°vel alvo necess√°ria para a an√°lise.")

source_identifier = DATASET_OPTIONS[selected_option_key]
uploaded_file = None
df = None

if source_identifier == "upload":
    uploaded_file = st.file_uploader("Para garantir a melhor an√°lise, seu arquivo deve conter a coluna alvo.", type=['csv', 'xlsx'])
    if uploaded_file: source_identifier = uploaded_file.name

# --- L√≥gica de Carregamento e Gerenciamento de Estado ---
if source_identifier and source_identifier != "upload":
    if 'current_source' not in st.session_state or st.session_state.current_source != source_identifier:
        st.session_state.current_source = source_identifier
        df_to_load = pd.read_csv(source_identifier) if not uploaded_file else (pd.read_excel(uploaded_file, engine='openpyxl') if uploaded_file.name.endswith('xlsx') else pd.read_csv(uploaded_file))
        st.session_state.df = df_to_load.copy()
        st.session_state.original_shape = df_to_load.shape
        st.session_state.data_modified = False
        st.session_state.applied_actions = []
        if 'action_plan' in st.session_state: del st.session_state.action_plan
    
    df = st.session_state.df

# --- O RESTO DO APP S√ì RODA SE UM DATAFRAME (df) EXISTIR ---
if df is not None:
    st.sidebar.header("üéØ Configura√ß√£o do Modelo")
    target_column = st.sidebar.selectbox("1. Selecione sua vari√°vel alvo:", options=[None] + df.columns.tolist())
    user_context = st.sidebar.text_area("2. Descreva o objetivo:", placeholder="Ex: Prever o risco de inadimpl√™ncia...")
    run_llm_analysis = st.sidebar.button("Gerar Plano de A√ß√£o com IA üß†")

    st.divider()
    st.header("2. An√°lise e A√ß√£o")
    st.subheader(f"Vis√£o Geral do Dataset: `{st.session_state.current_source.split('/')[-1]}`")
    st.dataframe(df.head())
    st.write(f"Shape atual: **{df.shape[0]} linhas** e **{df.shape[1]} colunas**.")

    if st.session_state.get('data_modified', False):
        report_text = gerar_texto_relatorio(st.session_state.current_source, st.session_state.original_shape, df.shape, target_column, user_context, st.session_state.applied_actions)
        zip_data = criar_pacote_zip(df, report_text, st.session_state.current_source)
        st.download_button(
           label="Baixar Pacote de Entrega (CSV + Relat√≥rio) üì¶",
           data=zip_data,
           file_name=f"entrega_{st.session_state.current_source.split('/')[-1].split('.')[0]}.zip",
           mime='application/zip',
           use_container_width=True
        )

    achados_estruturados = []
    resultado_nulos = analisar_nulos(df)
    if resultado_nulos: achados_estruturados.append(resultado_nulos)
    features_df = df.drop(columns=[target_column]) if target_column and target_column in df.columns else df
    for col in features_df.columns:
        resultado_outliers = analisar_outliers(features_df[col])
        if resultado_outliers: achados_estruturados.append(resultado_outliers)

    st.subheader("Dossi√™ de Evid√™ncias (An√°lise Algor√≠tmica)")
    if not achados_estruturados:
        st.success("A an√°lise algor√≠tmica inicial n√£o encontrou problemas significativos.")
    else:
        st.info("Os seguintes pontos foram identificados e ser√£o enviados ao especialista de IA:")
        st.json(achados_estruturados, expanded=False)

    if run_llm_analysis:
        if not LLM_OK: st.error("A API do LLM n√£o est√° configurada. Verifique seu arquivo .streamlit/secrets.toml.")
        elif not target_column or not user_context: st.error("Por favor, selecione a vari√°vel alvo e descreva o objetivo do modelo na barra lateral.")
        else:
            with st.spinner("üß† O especialista de IA est√° analisando o dossi√™ e preparando seu plano de a√ß√£o..."):
                texto_dos_achados = formatar_achados_para_prompt(achados_estruturados)
                plano_de_acao_json_str = gerar_plano_de_acao_com_llm(target_column, user_context, texto_dos_achados)
                try:
                    plano = json.loads(plano_de_acao_json_str)
                    if "error" in plano: st.error(f"A API retornou um erro: {plano['error']}")
                    st.session_state.action_plan = plano.get("action_plan", [])
                except json.JSONDecodeError:
                    st.error("A IA retornou uma resposta em um formato JSON inv√°lido."); st.code(plano_de_acao_json_str)
                    st.session_state.action_plan = []
                st.rerun()

    if 'action_plan' in st.session_state and st.session_state.action_plan:
        st.subheader("‚úÖ Plano de A√ß√£o Interativo", divider='rainbow')
        for i, action in enumerate(list(st.session_state.action_plan)):
            col1, col2 = st.columns([3, 1])
            with col1:
                st.markdown(f"**A√ß√£o:** `{action.get('action_code', 'N/A')}` na coluna **`{action.get('column', 'N/A')}`**")
                st.info(f"**Justificativa da IA:** {action.get('justification', 'N/A')}")
            with col2:
                if st.button("Aplicar esta A√ß√£o ‚ú®", key=f"apply_{i}", use_container_width=True):
                    action_func = ACTION_MAP.get(action['action_code'])
                    if action_func:
                        st.session_state.applied_actions.append(action)
                        st.session_state.df = action_func(st.session_state.df, action['column'])
                        st.session_state.data_modified = True
                        st.session_state.action_plan.pop(i)
                        st.rerun()
                    else:
                        st.error(f"A√ß√£o '{action['action_code']}' n√£o implementada.")

else:
    st.info("Aguardando a sele√ß√£o de um dataset ou o upload de um arquivo para iniciar a an√°lise.")