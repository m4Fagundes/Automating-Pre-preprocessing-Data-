# app.py - Vers√£o Final com Sistema H√≠brido (Algoritmo + LLM)
# Autor: Gemini (com base nas suas ideias)
# Data: 03/10/2025

import streamlit as st
import pandas as pd
import numpy as np
from thefuzz import process
import openpyxl
import google.generativeai as genai
import json

# --- 1. CONFIGURA√á√ÉO INICIAL ---
st.set_page_config(layout="wide", page_title="Consultor de Dados IA", page_icon="üß†")

try:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
    LLM_OK = True
except (KeyError, AttributeError):
    LLM_OK = False

# --- 2. FUN√á√ïES DE AN√ÅLISE - AGORA RETORNAM DADOS ESTRUTURADOS ---
# --- MUDAN√áA CR√çTICA ---

def analisar_nulos(df):
    nulos = df.isnull().sum()[lambda x: x > 0]
    if not nulos.empty:
        return {"tipo": "Valores Nulos", "detalhes": nulos.to_dict()}
    return None

def analisar_inconsistencias(series):
    unique_values = series.dropna().unique().tolist()
    if len(unique_values) < 2: return None
    # L√≥gica de encontrar inconsist√™ncias... (simplificada para o exemplo)
    grupos = [] # Substitua pela sua l√≥gica real, ex: encontrar_inconsistencias_categoricas
    if grupos:
        return {"tipo": "Inconsist√™ncia Categ√≥rica", "coluna": series.name, "detalhes": {"grupos_sugeridos": grupos}}
    return None

def analisar_outliers(series):
    if pd.api.types.is_numeric_dtype(series):
        Q1, Q3 = series.quantile(0.25), series.quantile(0.75)
        IQR = Q3 - Q1
        limite_inferior, limite_superior = Q1 - 1.5 * IQR, Q3 + 1.5 * IQR
        outliers = series[(series < limite_inferior) | (series > limite_superior)]
        if not outliers.empty:
            return {
                "tipo": "Outliers", "coluna": series.name,
                "detalhes": {
                    "m√©todo": "IQR", "contagem": len(outliers),
                    "exemplos": outliers.head(3).tolist(), "limites": (limite_inferior, limite_superior)
                }
            }
    return None

# --- 3. FUN√á√ïES DE SUPORTE AO LLM ---

def formatar_achados_para_prompt(findings):
    """Transforma a lista de dicion√°rios de achados em um texto formatado."""
    if not findings:
        return "Nenhum problema algor√≠tmico significativo foi detectado."
    
    prompt_text = "Aqui est√£o os resultados detalhados da an√°lise algor√≠tmica:\n\n"
    for finding in findings:
        prompt_text += f"- **Tipo de Achado:** {finding.get('tipo', 'N/A')}\n"
        if 'coluna' in finding:
            prompt_text += f"  - **Coluna Afetada:** {finding['coluna']}\n"
        prompt_text += f"  - **Detalhes Quantitativos:**\n```json\n{json.dumps(finding['detalhes'], indent=2)}\n```\n\n"
    return prompt_text

def gerar_plano_de_acao_com_llm(target, user_prompt, findings_text):
    """Monta o prompt avan√ßado e chama o LLM."""
    model = genai.GenerativeModel('gemini-2.0-flash')

    master_prompt = f"""
    **Persona:** Voc√™ √© um Cientista de Dados S√™nior e consultor especialista em prepara√ß√£o de dados para Machine Learning.

    **Tarefa:** Sua tarefa √© analisar um dossi√™ de "evid√™ncias" gerado por algoritmos e, combinando isso com o objetivo de neg√≥cio do usu√°rio, criar um plano de a√ß√£o priorizado. Voc√™ deve agir como um filtro inteligente, focando apenas nos problemas mais cr√≠ticos.

    **Contexto do Problema (fornecido pelo usu√°rio):**
    - **Vari√°vel Alvo a ser prevista:** `{target}`
    - **Objetivo do Modelo:** "{user_prompt}"

    **Dossi√™ de Evid√™ncias (Resultados da An√°lise Algor√≠tmica):**
    {findings_text}

    **Suas Instru√ß√µes:**
    1.  **Analise o Dossi√™:** Revise todas as evid√™ncias quantitativas.
    2.  **Priorize:** Com base no **objetivo do modelo** do usu√°rio, identifique os 2 ou 3 problemas mais cr√≠ticos que ter√£o o maior impacto negativo se n√£o forem tratados. Ignore os problemas de baixo impacto.
    3.  **Crie um Plano de A√ß√£o:** Para cada problema cr√≠tico, forne√ßa uma recomenda√ß√£o clara e acion√°vel.
    4.  **Justifique com Dados:** Explique **por que** cada recomenda√ß√£o √© importante, usando os dados do dossi√™ e conectando-os diretamente ao objetivo do usu√°rio. Por exemplo, "Os outliers na coluna 'pre√ßo' s√£o cr√≠ticos porque seu objetivo √© ter um modelo preciso...".
    5.  **Formato:** Apresente a resposta em Markdown como um "Plano de A√ß√£o de Pr√©-processamento", com t√≠tulos claros para cada recomenda√ß√£o.
    """

    try:
        response = model.generate_content(master_prompt)
        return response.text
    except Exception as e:
        return f"Ocorreu um erro ao chamar a API do LLM: {e}"


st.title("üß† Consultor de Dados IA")
st.write("Um sistema h√≠brido que combina an√°lise algor√≠tmica com a intelig√™ncia de um LLM para criar seu plano de tratamento de dados.")

uploaded_file = st.file_uploader("Escolha um arquivo (.csv ou .xlsx)", type=['csv', 'xlsx'])

if uploaded_file is not None:
    try:
        df = pd.read_excel(uploaded_file, engine='openpyxl') if uploaded_file.name.endswith('xlsx') else pd.read_csv(uploaded_file)
        
        st.sidebar.header("üéØ Configura√ß√£o do Modelo")
        target_column = st.sidebar.selectbox("1. Selecione sua vari√°vel alvo:", options=[None] + df.columns.tolist())
        user_context = st.sidebar.text_area("2. Descreva o objetivo do seu modelo:", placeholder="Ex: Prever o risco de inadimpl√™ncia. O modelo precisa ser justo e explic√°vel.")
        run_llm_analysis = st.sidebar.button("Gerar Plano de A√ß√£o com IA üß†")

        st.divider()
        st.subheader("Visualiza√ß√£o dos Dados Carregados")
        st.dataframe(df.head())

       
        achados_estruturados = []
        
        resultado_nulos = analisar_nulos(df)
        if resultado_nulos: achados_estruturados.append(resultado_nulos)

        features_df = df.drop(columns=[target_column]) if target_column else df
        for col in features_df.columns:
            resultado_outliers = analisar_outliers(features_df[col])
            if resultado_outliers: achados_estruturados.append(resultado_outliers)

        st.subheader("Dossi√™ de Evid√™ncias (An√°lise Algor√≠tmica)")
        if not achados_estruturados:
            st.success("A an√°lise algor√≠tmica inicial n√£o encontrou problemas significativos.")
        else:
            st.info("Os seguintes pontos foram identificados e ser√£o enviados ao especialista de IA para an√°lise contextual:")
            st.json(achados_estruturados)
        
        if run_llm_analysis:
            if not LLM_OK:
                st.error("A API do LLM n√£o est√° configurada.")
            elif not target_column or not user_context:
                st.error("Por favor, selecione a vari√°vel alvo e descreva o objetivo do modelo na barra lateral.")
            else:
                with st.spinner("üß† O especialista de IA est√° analisando o dossi√™ e preparando seu plano de a√ß√£o..."):
                    texto_dos_achados = formatar_achados_para_prompt(achados_estruturados)
                    plano_de_acao = gerar_plano_de_acao_com_llm(
                        target=target_column,
                        user_prompt=user_context,
                        findings_text=texto_dos_achados
                    )
                    st.subheader("‚úÖ Plano de A√ß√£o de Pr√©-processamento", divider='rainbow')
                    st.markdown(plano_de_acao)

    except Exception as e:
        st.error(f"Ocorreu um erro geral: {e}")